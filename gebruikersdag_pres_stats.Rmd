---
title: "gebruikersdag"
author: "Steven Wink"
date: "April 3, 2016"
output: html_document
---

# Het rechter spectrum van BI
==============================
 ## 1: significantie, 2: visualizatie,  3: groeperen, 4: predictie 
 *** De statistische taal 'R' kan aangeroepen worden vanuit Diver.
 *** Enkele kleine voorbeeldjes over het gebruik van R om meer inzicht in data te krijgen. 

### Salaris dataset. 10 metingen die mogelijk invloed hebben op salaris.
### Autostoeltjes verkoop dataset. Verkoop data van 400 winkels en 10 metingen die mogelijk invloed hebben op de verkoop


 # 1: significantie
 * Het kwantificeren van hoe zeker we zijn over een meting of voorspelling
 ** Is er een verschil in het alcohol gehalte tussen de verschillende wijn soorten?
 ** Betekent dit verschil iets? (is het significant)
 



```{r, echo =FALSE}
rm(list=ls())
#http://www.statmethods.net/advgraphs/parameters.html
list.of.packages <- c("devtools", "ggplot2", "NMF")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(devtools)
library(ggplot2)
#install_github("vqv/ggbiplot")
library(ggbiplot)
library(NMF)

data(wine)

wine.c <- cbind(wine,wine.class)
```

Om het antwoord te vinden, zouden we simpelweg het gemiddelde kunnen berekenen:
```{r }


aggregate(Alcohol  ~ wine.class, data = wine.c, FUN = mean)


```

Maar is dit nou anders? Kunnen we deze gemiddelden bij de batch van volgend jaar weer verwachten?


```{r }


p <- ggplot(data = wine.c, aes( x = wine.class, y = Alcohol )) + geom_jitter(aes(color = wine.class), size = 4) + theme_minimal() 
print(p)
p  +  ylim(c(0,20))

lm.out <- lm( Alcohol ~ wine.class, data = wine.c) 
summary(lm.out) 

```


Welke meting hangt het meest samen met alcohol percentage?
Is dit onafhankelijk van het soort druif?


```{r}

# volgende hoogste correlaties met kwaliteit? hoe verhouden deze zich dan? is er een optimale combinatie van deze?

cor(wine.c[, -14])[,1] # Alcohol is gecoroleerd aan bijvoorbeeld Proline

p <- ggplot(data = wine.c, aes( x = Alcohol, y = Proline, color = wine.class )) + geom_point(size= 3) + theme_minimal() 
print(p) 
p + geom_smooth(method = 'lm') # voeg een regressielijntje toe

# non linear method
p + geom_smooth(span = 1 ) # voeg een regressielijntje toe



```


 
 # 2: visualizatie & 3: groeperen
  
  * Hoe kunnen wij nu alle alle 13 variabelen grafisch weergeven? 
  * Exploratie/ nieuwe inzichten
  * quality control van individuele druif batchen
  
```{r, echo=FALSE, eval= FALSE}



# Er is altijd de mogelijkheid om alles vs alles te plotten. Bij 13 dimensies:
pairs(wine.c, col = wine.c$wine.class) # ook hier moelijkt te zien - dimensie reductie


wine.pca <- prcomp(wine.c[, -14], scale. = TRUE)


ggbiplot(wine.pca, obs.scale = 2, var.scale = 1,
  ellipse = TRUE, circle = TRUE, varname.size = 6) +
  scale_color_discrete(name = '') + theme_minimal() + 
  theme(legend.direction = 'horizontal', legend.position = 'top')

 ggbiplot(wine.pca, obs.scale = 1.5, var.scale = 1,
  ellipse = TRUE, circle = TRUE,
  group = as.factor(wine.c[, 14]), varname.size = 6, ) +
  scale_color_discrete(name = '') + theme_minimal() + ylim(c(-5,5)) + xlim( c(-5,5)) + 
  theme(legend.direction = 'horizontal', legend.position = 'top')  

 
 


wine.c.s <- scale(wine.c[, -14])

aheatmap(  wine.c.s,distfun = "euclidean", annRow = wine.c$wine.class)




```

 # 3: predictie
  
  * Het gebruik van bestaande data om iets te voorspellen over het onbekende.
  * Alles meten zou duur kunnen zijn, wat moeten we minimaal meten voor een goede predictie?
  * Hoe goed is onze predictie?
  
  
```{r, echo=FALSE, eval= FALSE}
 install.packages("gbm")

require(gbm)

wine.c.s <- data.frame(cbind(wine.c.s, wine.c$wine.class))
set.seed(235)
colnames(wine.c.s)[14] <- "wine.class"
trainInd <- sample(1:nrow(wine.c.s), round(0.7 * nrow(wine.c.s), digits = 0))

boost.wine = gbm(wine.class ~ ., data = wine.c.s[trainInd, ], distribution = "gaussian", 
    n.trees = 500, shrinkage = 0.01, interaction.depth = 3)
summary(boost.wine)



predmat = predict(boost.wine, newdata = wine.c.s[-trainInd, ], n.trees =500, type = 'response' )
predmat <- round(predmat, digits= 0)

wine.c.s$wine.class[-trainInd]
predmat[ predmat == 2   ] <- "barolo"
predmat[ predmat == 3   ] <- "grignolino"
predmat[ predmat == 1   ] <- "barbera"


t.out<-table(predmat, wine.c.s[ -trainInd, "wine.class"])
sum(diag(t.out))/ sum(t.out) 






```  
  
  
  
